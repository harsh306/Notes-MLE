@misc{deep_convex_opt,
    author = {Reza Zadeh},
    year = {2016},
    url = {https://www.oreilly.com/ideas/the-hard-thing-about-deep-learning},
}


@misc{param_model,
    url = {https://en.wikipedia.org/wiki/Parametric_model},
}

@misc{why-mle,
    url = {https://blog.metaflow.fr/ml-notes-why-the-log-likelihood-24f7b6c40f83},
}

 https://www.youtube.com/watch?v=3RVGrz7MjMg
 
@misc{nips-talk,
    url = {https://blog.metaflow.fr/ml-notes-why-the-log-likelihood-24f7b6c40f83},
}

@misc{why-iid,
    url = {https://stats.stackexchange.com/questions/213464/on-the-importance-of-the-i-i-d-assumption-in-statistical-learning},
}

@misc{mle-density,
    url = {https://machinelearningmastery.com/what-is-maximum-likelihood-estimation-in-machine-learning/},
}





@misc{iter,
    url = {https://stats.stackexchange.com/questions/212619/why-is-gradient-descent-required},
}



@misc{mit,
    author = {Jeremy Orloff and Jonathan Bloom},
    year = {2014},
    url = {https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/},
}

@misc{reg,
    author = {Brian Keng },
    year = {2016},
    url = {http://bjlkeng.github.io/posts/probabilistic-interpretation-of-regularization/},
}


@misc{mse-eq,
    url = {https://stats.stackexchange.com/questions/9801/analytical-solution-to-linear-regression-coefficient-estimates},
}



@misc{mle-map,
    url = {https://wiseodd.github.io/techblog/2017/01/01/mle-vs-map/},
}


@misc{why-lse,
    url = {https://towardsdatascience.com/ml-notes-why-the-least-square-error-bf27fdd9a721},
}


@misc{NLL,
    author = {Lj Miranda},
    year = {2017},
    url = {https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/},
}

